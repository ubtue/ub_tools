# Based on code generated by AI
import configparser
import jq
import json
from pydantic import BaseModel, Field, PrivateAttr, validator
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from pysolr import Solr
from typing import List,Dict,Optional

class SolrConfig(BaseModel):
      host: str = "localhost"
      port: int = Field(default=8983, gt=0, le=65535)
      collection:  Optional[str] = Field(default="biblio")
      max_records: int = Field(default=100)

      @classmethod
      def load_config(cls, config_file: str):
          config = configparser.ConfigParser()
          config.read(config_file)
          if not config.has_section('Solr'):
              raise configparser.NoSectionError('Solr')

          solr_data = dict(config['Solr'])

          if 'port' in solr_data:
              solr_data['port'] = int(solr_data['port'])

          if 'max_records' in solr_data:
              solr_data['max_records'] = int(solr_data['max_records'])

          return cls(**solr_data)


class SolrRetriever(BaseRetriever):
    solr_url : str = ''
    client: Solr = None
    solr_config : SolrConfig = SolrConfig()
    k: int = 100
    def __init__(self, config_file : str = 'rag_config.ini'):
       super().__init__()
       self.solr_config = SolrConfig.load_config(config_file)
       self.solr_url = f"http://{self.solr_config.host}:{self.solr_config.port}/solr/{self.solr_config.collection}"

    def _get_relevant_documents(self, query: str) -> List[Document]:
        if not self.client:
            self.client = Solr(self.solr_url)

        results = self.client.search(query, fl='*', rows=self.k)
        docs = []
        for doc in results.docs:
            content = doc.get('fullrecord', '') or ''
            docs.append(Document(
                page_content=str(content),
                metadata={
                    **{k: v for k, v in doc.items() if k in ['id', 'author', 'title', 'year']}
                }
            ))
        return docs


class SolrBatchRetriever(SolrRetriever):
    _next_cursor : str = PrivateAttr(default='*')
    _query : str = PrivateAttr(default='*:*')
    retrieved_records : int = 0

    def __init__(self, query : str, config_file : str = 'rag_config.ini') :
      super().__init__(config_file)
      self._query = query
      self

    def _get_relevant_documents(self, query: str) -> List[Document]:
       if not self.client:
           self.client = Solr(self.solr_url)

       if self.retrieved_records > self.solr_config.max_records:
           self._next_cursor = '*'
           return []

       params = {
          'q' :  query,
          'rows' : self.k,
          'sort' : 'id desc',
          'cursorMark' : self._next_cursor,
          'fl' : '*'
       }

       results = self.client.search(**params)
       docs = []
       if results.nextCursorMark == self._next_cursor:
           self._next_cursor = '*'
           return []
       else:
           self._next_cursor = results.nextCursorMark

       for doc in results.docs:
           content = doc.get('fullrecord', '') or ''
           lok_remover = jq.compile('.fields |= map(with_entries(select(.key | test("LOK") | not)))')
           content = lok_remover.input_value(json.loads(content)).text()
           docs.append(Document(
               page_content=content,
               metadata={
                   **{k: v for k, v in doc.items() if k in ['id', 'author', 'title', 'year']}
               }
           ))

       self.retrieved_records += len(results.docs)
       return docs


    def get_next_batch(self):
        return self._get_relevant_documents(self._query)


if __name__ == "__main__":
#  solr_retriever = SolrRetriever()
#  docs = solr_retriever._get_relevant_documents("*:*")
#  print(docs)

    solr_retriever = SolrBatchRetriever('-id:L*')
    while True:
       docs = solr_retriever.get_next_batch()
       if not docs:
           break
       print(docs)

